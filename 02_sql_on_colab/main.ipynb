{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('trust_stream': conda)"
  },
  "interpreter": {
   "hash": "167c1561c174e91518859240caf65cbf556e74a4dcd18fddf53afddc95ecd2f9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "source": [
    "## SQL Hepler Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_to_sqlDB(input_df: pd.DataFrame,\n",
    "                table_name: str,\n",
    "                db_name: str = 'default.db') -> None:\n",
    "\n",
    "    '''Take a Pandas dataframe `input_df` and upload it to `table_name` SQLITE table\n",
    "\n",
    "    Args:\n",
    "        input_df (pd.DataFrame): Dataframe containing data to upload to SQLITE\n",
    "        table_name (str): Name of the SQLITE table to upload to\n",
    "        db_name (str, optional): Name of the SQLITE Database in which the table is created. \n",
    "                                 Defaults to 'default.db'.\n",
    "    '''\n",
    "\n",
    "    # Setup local logging\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Find columns in the dataframe\n",
    "    cols = input_df.columns\n",
    "    cols_string = ','.join(cols)\n",
    "    val_wildcard_string = ','.join(['?'] * len(cols))\n",
    "\n",
    "    # Connect to a DB file if it exists, else crete a new file\n",
    "    con = sqlite3.connect(db_name)\n",
    "    cur = con.cursor()\n",
    "    logging.info(f'SQL DB {db_name} created')\n",
    "\n",
    "    # Create Table\n",
    "    sql_string = \"\"\"CREATE TABLE {} ({});\"\"\".format(table_name, cols_string)\n",
    "    cur.execute(sql_string)\n",
    "    logging.info(f'SQL Table {table_name} created with {len(cols)} columns')\n",
    "\n",
    "    # Upload the dataframe\n",
    "    rows_to_upload = input_df.to_dict(orient='split')['data']\n",
    "    sql_string = \"\"\"INSERT INTO {} ({}) VALUES ({});\"\"\".format(table_name, \n",
    "                                                               cols_string,\n",
    "                                                               val_wildcard_string)\n",
    "    cur.executemany(sql_string, rows_to_upload)\n",
    "    logging.info(f'{len(rows_to_upload)} uploaded to {table_name}')\n",
    "\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def sql_query_to_pd(sql_text: str, db_name: str ='default.db') -> pd.DataFrame:\n",
    "    '''Execute an SQL query and return the results as a pandas dataframe\n",
    "\n",
    "    Args:\n",
    "        sql_text (str): SQL query string to execute\n",
    "        db_name (str, optional): Name of the SQLITE Database to execute the query in.\n",
    "                                 Defaults to 'default.db'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Results of the SQL query in a pandas dataframe\n",
    "    '''    \n",
    "    # Connect to the SQL DB\n",
    "    con = sqlite3.connect(db_name)\n",
    "\n",
    "    # Execute the SQL query\n",
    "    cursor = con.execute(sql_text)\n",
    "\n",
    "    # Fetch the data and column names\n",
    "    result_data = cursor.fetchall()\n",
    "    cols = [description[0] for description in cursor.description]\n",
    "\n",
    "    # Close the connection\n",
    "    con.close()\n",
    "\n",
    "    # Return as a dataframe\n",
    "    return pd.DataFrame(result_data, columns=cols)"
   ]
  },
  {
   "source": [
    "## Execute Query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a dataframe\n",
    "# Dataset from https://www.kaggle.com/gpreda/covid-world-vaccination-progress\n",
    "input_df = pd.read_csv('country_vaccinations.csv')\n",
    "\n",
    "# Upload the dataframe to a SQL Table\n",
    "pd_to_sqlDB(input_df,\n",
    "            table_name='country_vaccinations',\n",
    "            db_name='default.db')\n",
    "\n",
    "# Exectue a SQL query\n",
    "sql_string = \"\"\"\n",
    "    SELECT country, SUM(total_vaccinations) as total_vaccinated\n",
    "    FROM country_vaccinations \n",
    "    WHERE total_vaccinations IS NOT NULL \n",
    "    GROUP BY country\n",
    "    ORDER BY total_vaccinated DESC\n",
    "\"\"\"\n",
    "\n",
    "result_df = sql_query_to_pd(sql_string, db_name='default.db')\n",
    "print(result_df)"
   ]
  }
 ]
}